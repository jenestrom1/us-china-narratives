{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e131224a-8af1-476d-a952-c551c5487480",
      "metadata": {
        "tags": [],
        "id": "e131224a-8af1-476d-a952-c551c5487480",
        "outputId": "4eeb9b0c-7a50-4dab-aa12-ff56505a1505"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/Jullen18/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "\n",
        "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import make_scorer, precision_score, f1_score, recall_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pdfminer #used PDF package\n",
        "\n",
        "import string\n",
        "\n",
        "import spacy\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd5aaab-5915-4b2f-bf89-44370c0c35c4",
      "metadata": {
        "id": "3dd5aaab-5915-4b2f-bf89-44370c0c35c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3e10ff1d-a2fb-45dc-905e-ac930c7ae517",
      "metadata": {
        "id": "3e10ff1d-a2fb-45dc-905e-ac930c7ae517"
      },
      "source": [
        "## **Trying out Pdfminer and pre-processing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25634995-dc52-43e3-840e-46ce3c222484",
      "metadata": {
        "tags": [],
        "id": "25634995-dc52-43e3-840e-46ce3c222484",
        "outputId": "f7f9baa3-41e6-4cb9-955a-71a41b9989e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'20191125'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdfminer.__version__ #confirming latest version, per https://stackoverflow.com/questions/25665/python-module-for-converting-pdf-to-text and https://pypi.org/project/pdfminer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f56f7b-a88d-4ea3-bdec-cfdd119b4455",
      "metadata": {
        "tags": [],
        "id": "62f56f7b-a88d-4ea3-bdec-cfdd119b4455"
      },
      "outputs": [],
      "source": [
        "#testing out pdfminer, code from https://stackoverflow.com/questions/25665/python-module-for-converting-pdf-to-text\n",
        "\n",
        "import sys\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "import io\n",
        "\n",
        "def pdfparser(data):\n",
        "\n",
        "    fp = open(data, 'rb')\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    retstr = io.StringIO()\n",
        "    #codec = 'utf-8'\n",
        "    laparams = LAParams()\n",
        "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
        "    # Create a PDF interpreter object.\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "    # Process each page contained in the document.\n",
        "\n",
        "    for page in PDFPage.get_pages(fp):\n",
        "        interpreter.process_page(page)\n",
        "        data =  retstr.getvalue()\n",
        "\n",
        "    return(data) #changed this to return data instead\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#    pdfparser(sys.argv[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b09f3690-336b-4d4c-816b-ea4fc4c11ae3",
      "metadata": {
        "tags": [],
        "id": "b09f3690-336b-4d4c-816b-ea4fc4c11ae3"
      },
      "outputs": [],
      "source": [
        "pdf_list = [\"nss2002.pdf\", \"The National Security Strategy-- 2006.pdf\", \"NSS2010.pdf\", \"NSS2015.pdf\", \"NSS2017.pdf\", \"Biden-Harris Administration's National Security Strategy 2022.pdf\"]\n",
        "text_list = []\n",
        "\n",
        "for i in pdf_list:\n",
        "    text_list.append(pdfparser(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14946ab8-2bb7-400a-b5c8-24129a1a6755",
      "metadata": {
        "tags": [],
        "id": "14946ab8-2bb7-400a-b5c8-24129a1a6755"
      },
      "outputs": [],
      "source": [
        "nss_df = pd.DataFrame(data={\"file_name\": pdf_list, \"text\":text_list})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03f40e7-b954-4678-b534-aa70a05f6159",
      "metadata": {
        "tags": [],
        "id": "f03f40e7-b954-4678-b534-aa70a05f6159",
        "outputId": "9027a5e2-ff05-49aa-990e-343c7830cab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nss2002.pdf | number of characters: 84646\n",
            "The National Security Strategy-- 2006.pdf | number of characters: 134565\n",
            "NSS2010.pdf | number of characters: 188938\n",
            "NSS2015.pdf | number of characters: 104621\n",
            "NSS2017.pdf | number of characters: 169715\n",
            "Biden-Harris Administration's National Security Strategy 2022.pdf | number of characters: 162507\n"
          ]
        }
      ],
      "source": [
        "#getting a sense of size of documents:\n",
        "for i in range(len(nss_df[\"text\"])):\n",
        "    print(nss_df[\"file_name\"].iloc[i] + \" | number of characters: \" + str(len(nss_df[\"text\"].iloc[i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eca63fe-14fa-4601-b4af-0dcbba6d9c10",
      "metadata": {
        "tags": [],
        "id": "2eca63fe-14fa-4601-b4af-0dcbba6d9c10"
      },
      "outputs": [],
      "source": [
        "nss_df[\"year\"]=nss_df[\"file_name\"]\n",
        "nss_df[\"year\"] = nss_df[\"year\"].str[-8:-4] #learned about string slice method here: https://stackoverflow.com/questions/48773767/how-to-slice-column-values-in-python-pandas-dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df57313-0b2d-4583-8ce4-ab6c36651d33",
      "metadata": {
        "tags": [],
        "id": "1df57313-0b2d-4583-8ce4-ab6c36651d33"
      },
      "outputs": [],
      "source": [
        "text_tokenized = []\n",
        "for i in nss_df[\"text\"]:\n",
        "    text_tokenized.append(word_tokenize(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89f2b543-00e1-44ac-99b7-459be3d7ef5d",
      "metadata": {
        "tags": [],
        "id": "89f2b543-00e1-44ac-99b7-459be3d7ef5d"
      },
      "outputs": [],
      "source": [
        "nss_df[\"text_tokenized\"]=text_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d185ffaa-57db-49b8-a223-c2b8ad482c6b",
      "metadata": {
        "tags": [],
        "id": "d185ffaa-57db-49b8-a223-c2b8ad482c6b"
      },
      "outputs": [],
      "source": [
        "text_tokenized_stopwords = []\n",
        "for i in nss_df[\"text_tokenized\"]:\n",
        "    for j in i:\n",
        "        if j in stopwords.words(\"english\"):\n",
        "            i.remove(j)\n",
        "    text_tokenized_stopwords.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0d9fb4-c2a9-4296-9300-5aa71fb493ca",
      "metadata": {
        "tags": [],
        "id": "fb0d9fb4-c2a9-4296-9300-5aa71fb493ca"
      },
      "outputs": [],
      "source": [
        "nss_df[\"text_tokenized_stopwords\"]= text_tokenized_stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "468d89f8-e5d1-482d-b034-bc09e168106f",
      "metadata": {
        "tags": [],
        "id": "468d89f8-e5d1-482d-b034-bc09e168106f",
        "outputId": "7bd3dc02-7a72-4198-e77a-27b505e1be4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abcdefghijklmnopqrstuvwxyz\n",
            "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
            "0123456789\n",
            "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\n"
          ]
        }
      ],
      "source": [
        "#using string lists of alphanumeric characters to further limit tokens, suggested at: https://stackoverflow.com/questions/51265716/is-there-a-list-of-all-alphanumeric-signs-in-python\n",
        "print(string.ascii_lowercase)\n",
        "print(string.ascii_uppercase)\n",
        "print(string.digits)\n",
        "checker = string.ascii_uppercase + string.ascii_lowercase  + string.digits\n",
        "print(checker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdab2903-4b26-404a-8b92-2e126481c5af",
      "metadata": {
        "tags": [],
        "id": "fdab2903-4b26-404a-8b92-2e126481c5af"
      },
      "outputs": [],
      "source": [
        "#only including alphanumerical characters and lowercase\n",
        "\n",
        "text_tokenized_stopwords_alphanumerical = []\n",
        "for i in nss_df[\"text_tokenized_stopwords\"]: #removing non-alphanumerical characters\n",
        "    for j in i:\n",
        "        for k in j:\n",
        "            if k not in checker:\n",
        "                i.remove(j)\n",
        "                break\n",
        "    text_tokenized_stopwords_alphanumerical.append(i)\n",
        "\n",
        "for i in text_tokenized_stopwords_alphanumerical: #making everything lowercase\n",
        "    for j in range(len(i)):\n",
        "        i[j] = i[j].lower()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5888fad-c1ff-4d58-8984-f163c8ce363f",
      "metadata": {
        "tags": [],
        "id": "a5888fad-c1ff-4d58-8984-f163c8ce363f"
      },
      "outputs": [],
      "source": [
        "nss_df[\"text_tokenized_stopwords_alphanumerical\"]= text_tokenized_stopwords_alphanumerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637bd48b-7c84-46e5-ad81-eeebe92d22d2",
      "metadata": {
        "tags": [],
        "id": "637bd48b-7c84-46e5-ad81-eeebe92d22d2",
        "outputId": "5c27411b-8f80-4164-c904-05046fbf62b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "      <th>year</th>\n",
              "      <th>text_tokenized</th>\n",
              "      <th>text_tokenized_stopwords</th>\n",
              "      <th>text_tokenized_stopwords_alphanumerical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nss2002.pdf</td>\n",
              "      <td>The National\\n\\nSecurity Strategy\\n\\nof the \\n...</td>\n",
              "      <td>2002</td>\n",
              "      <td>[the, national, security, strategy, united, st...</td>\n",
              "      <td>[the, national, security, strategy, united, st...</td>\n",
              "      <td>[the, national, security, strategy, united, st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The National Security Strategy-- 2006.pdf</td>\n",
              "      <td>\\n\\n \\n\\n \\n\\n \\n\\nTABLE OF CONTENTS \\n\\nO...</td>\n",
              "      <td>2006</td>\n",
              "      <td>[table, of, contents, overview, america, natio...</td>\n",
              "      <td>[table, of, contents, overview, america, natio...</td>\n",
              "      <td>[table, of, contents, overview, america, natio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NSS2010.pdf</td>\n",
              "      <td>NAT IONA L  SECU R IT Y \\n\\nSTR ATEGY\\n\\nMay 2...</td>\n",
              "      <td>2010</td>\n",
              "      <td>[nat, iona, l, secu, r, it, y, str, ategy, may...</td>\n",
              "      <td>[nat, iona, l, secu, r, it, y, str, ategy, may...</td>\n",
              "      <td>[nat, iona, l, secu, r, it, y, str, ategy, may...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NSS2015.pdf</td>\n",
              "      <td>NATIONAL  SECURITY \\n\\nSTRATEGY\\n\\nF EBRUA RY ...</td>\n",
              "      <td>2015</td>\n",
              "      <td>[national, security, strategy, f, ebrua, ry, 2...</td>\n",
              "      <td>[national, security, strategy, f, ebrua, ry, 2...</td>\n",
              "      <td>[national, security, strategy, f, ebrua, ry, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NSS2017.pdf</td>\n",
              "      <td>N������� S������� \\n\\nS�������\\n\\nof the Unite...</td>\n",
              "      <td>2017</td>\n",
              "      <td>[united, states, america, d, e, c, e, m, b, e,...</td>\n",
              "      <td>[united, states, america, d, e, c, e, m, b, e,...</td>\n",
              "      <td>[united, states, america, d, e, c, e, m, b, e,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   file_name  \\\n",
              "0                                nss2002.pdf   \n",
              "1  The National Security Strategy-- 2006.pdf   \n",
              "2                                NSS2010.pdf   \n",
              "3                                NSS2015.pdf   \n",
              "4                                NSS2017.pdf   \n",
              "\n",
              "                                                text  year  \\\n",
              "0  The National\\n\\nSecurity Strategy\\n\\nof the \\n...  2002   \n",
              "1  \n",
              "\n",
              "\n",
              " \\n\\n \\n\\n \\n\\n \\n\\nTABLE OF CONTENTS \\n\\nO...  2006   \n",
              "2  NAT IONA L  SECU R IT Y \\n\\nSTR ATEGY\\n\\nMay 2...  2010   \n",
              "3  NATIONAL  SECURITY \\n\\nSTRATEGY\\n\\nF EBRUA RY ...  2015   \n",
              "4  N������� S������� \\n\\nS�������\\n\\nof the Unite...  2017   \n",
              "\n",
              "                                      text_tokenized  \\\n",
              "0  [the, national, security, strategy, united, st...   \n",
              "1  [table, of, contents, overview, america, natio...   \n",
              "2  [nat, iona, l, secu, r, it, y, str, ategy, may...   \n",
              "3  [national, security, strategy, f, ebrua, ry, 2...   \n",
              "4  [united, states, america, d, e, c, e, m, b, e,...   \n",
              "\n",
              "                            text_tokenized_stopwords  \\\n",
              "0  [the, national, security, strategy, united, st...   \n",
              "1  [table, of, contents, overview, america, natio...   \n",
              "2  [nat, iona, l, secu, r, it, y, str, ategy, may...   \n",
              "3  [national, security, strategy, f, ebrua, ry, 2...   \n",
              "4  [united, states, america, d, e, c, e, m, b, e,...   \n",
              "\n",
              "             text_tokenized_stopwords_alphanumerical  \n",
              "0  [the, national, security, strategy, united, st...  \n",
              "1  [table, of, contents, overview, america, natio...  \n",
              "2  [nat, iona, l, secu, r, it, y, str, ategy, may...  \n",
              "3  [national, security, strategy, f, ebrua, ry, 2...  \n",
              "4  [united, states, america, d, e, c, e, m, b, e,...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nss_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427b44b9-5e34-4b2e-8b7a-110970f885fb",
      "metadata": {
        "tags": [],
        "id": "427b44b9-5e34-4b2e-8b7a-110970f885fb",
        "outputId": "c187538b-f568-4475-96da-0d3c555b04f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['inter-american', 'development', 'bank', 'president', 'bush', 'march', '14', '2002', 'a', 'world', 'some', 'live', 'comfort', 'this', 'administration', 'goal', 'help', 'unleash', 'plenty', 'half', 'the', 'human', 'race', 'lives', 'less', '2', 'a', 'day', 'neither', 'just', 'nor', 'stable', 'including', 'all', 'the', 'world', 'poor', 'an', 'expanding', 'circle']\n",
            "['they', 'pursue', 'wmd', 'their', 'peril', '_____________________________________________________________________________________________________________________', 'national', 'security', 'strategy', '24', 'vi', 'ignite', 'a', 'new', 'era', 'global', 'economic', 'growth', 'free', 'markets', 'free', 'trade', 'a', 'summary', 'national', 'security', 'strategy', '2002', 'promoting', 'free', 'fair', 'trade', 'long', 'been', 'a', 'bedrock', 'tenet', 'american', 'foreign', 'policy']\n",
            "['nonstate', 'actors', 'corporations', 'foundations', 'nongovern-', 'mental', 'organizations', 'universities', 'think', 'tanks', 'faith-based', 'organizations', 'increasingly', 'distinct', 'role', 'play', 'diplomatic', 'development', 'issues', 'to', 'accomplish', 'goals', 'table', 'of', 'contents', 'diplomatic', 'personnel', 'missions', 'must', 'expanded', 'home', 'abroad', 'support', 'increasingly', 'transnational', 'nature', '21st', 'century', 'security', 'challenges']\n",
            "['domain', 'with', 'congress', 'must', 'end', 'sequestration', 'enact', 'critical', 'reforms', 'build', 'versatile', 'responsive', 'force', 'prepared', 'diverse', 'set', 'contingencies', 'we', 'protect', 'investment', 'foundational', 'capabilities', 'like', 'nuclear', 'deterrent', 'grow', 'investment', 'crucial', 'capabilities', 'like', 'cyber', 'space', 'intelligence', 'surveillance', 'reconnaissance', 'we', 'safeguard', 'science', 'technology', 'base']\n",
            "['competition', 'our', 'ies', 'not', 'ght', 'us', 'our', 'terms', 'we', 'raise', 'our', 'competitive', 'game', 'meet', 'challenge', 'tect', 'american', 'interests', 'advance', 'our', 'values', 'our', 'diplomatic', 'intelligence', 'military', 'nomic', 'agencies', 'not', 'kept', 'pace', 'changes', 'character', 'competition', 'america', 'tary', 'must', 'prepared', 'operate', 'across', 'full']\n",
            "['organizations', 'to', 'better', 'address', 'competition', 'embracing', 'new', 'data', 'tools', 'enhancing', 'integration', 'open', 'source', 'material', '(', ')', 'enhancing', 'u.s.', 'global', 'early', 'warning', 'forecasting', 'infectious', 'disease', 'threats', 'pandemics', 'by', 'increasing', 'support', 'for', 'the', 'centers', 'for', 'disease', 'control', 'prevention', '’', '(', 'cdc', ')']\n"
          ]
        }
      ],
      "source": [
        "#checking random locations\n",
        "for i in nss_df[\"text_tokenized_stopwords_alphanumerical\"]:\n",
        "    index_area = random.randint(0,len(i))\n",
        "    print(i[index_area-20:index_area+20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e384c49c-18d0-46ec-9874-aeb4f4812e22",
      "metadata": {
        "tags": [],
        "id": "e384c49c-18d0-46ec-9874-aeb4f4812e22"
      },
      "source": [
        "## **Dictionary-based Methods**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c847d614-483c-4a2a-9e86-04115acf1440",
      "metadata": {
        "tags": [],
        "id": "c847d614-483c-4a2a-9e86-04115acf1440"
      },
      "outputs": [],
      "source": [
        "#let's begin by looking at one document and then expanding\n",
        "\n",
        "nss_2022_tokenized = nss_df[\"text_tokenized_stopwords_alphanumerical\"].iloc[5]\n",
        "\n",
        "nss_2022_counter = Counter()\n",
        "\n",
        "for token in nss_2022_tokenized:\n",
        "    nss_2022_counter[token] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46cc96d3-263c-406c-b1b4-103842fd1f04",
      "metadata": {
        "tags": [],
        "id": "46cc96d3-263c-406c-b1b4-103842fd1f04",
        "outputId": "b329b3fe-0f83-4bf9-ca09-fc8e3d7a2a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3170\n",
            "9\n",
            "58\n",
            "32\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(len(nss_2022_counter))\n",
        "print(nss_2022_counter[\"china\"])\n",
        "print(nss_2022_counter[\"russia\"])\n",
        "print(nss_2022_counter[\"ukraine\"])\n",
        "print(nss_2022_counter[\"assertive\"]) #probably not the best NSS for this, then, let's try Trump's 2017 NSS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01aac3c-3c03-464b-8beb-d645eef8bcf5",
      "metadata": {
        "tags": [],
        "id": "e01aac3c-3c03-464b-8beb-d645eef8bcf5",
        "outputId": "dc79bcf2-e4e4-49c6-968e-d39960593bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3708\n",
            "33\n",
            "22\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "nss_2017_tokenized = nss_df[\"text_tokenized_stopwords_alphanumerical\"].iloc[4]\n",
        "\n",
        "nss_2017_counter = Counter()\n",
        "\n",
        "for token in nss_2017_tokenized:\n",
        "    nss_2017_counter[token] += 1\n",
        "\n",
        "\n",
        "print(len(nss_2017_counter))\n",
        "print(nss_2017_counter[\"china\"])\n",
        "print(nss_2017_counter[\"russia\"])\n",
        "print(nss_2017_counter[\"ukraine\"])\n",
        "print(nss_2017_counter[\"assertive\"]) #hmm, China is definitely more important, but \"assertive\" is not as prominent\n",
        "#probably representing the idea the idea of \"language slippage\" here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5b8eff-9342-42b1-b5f6-4c16bc35eeb4",
      "metadata": {
        "tags": [],
        "id": "cc5b8eff-9342-42b1-b5f6-4c16bc35eeb4"
      },
      "outputs": [],
      "source": [
        "#let's do this for all of them\n",
        "nss_token_dict = {}\n",
        "for i in range(len(nss_df[\"text_tokenized_stopwords_alphanumerical\"])):\n",
        "    temp_counter = Counter()\n",
        "    temp_tokenized = nss_df[\"text_tokenized_stopwords_alphanumerical\"].iloc[i]\n",
        "    for token in temp_tokenized:\n",
        "        temp_counter[token] += 1\n",
        "    nss_token_dict[str(nss_df[\"year\"].iloc[i])] = temp_counter #inspired by https://stackoverflow.com/questions/1060090/changing-variable-names-with-python-for-loops\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e6546aa-7382-4c01-add1-650ac7443812",
      "metadata": {
        "tags": [],
        "id": "9e6546aa-7382-4c01-add1-650ac7443812",
        "outputId": "4d5c3ea6-6b26-4718-c2ec-0fafcd8e1b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year: 2002\n",
            "'china' count: 18\n",
            "'russia' count: 14\n",
            "'ukraine' count: 0\n",
            "'assertive' count: 0\n",
            "--------------------\n",
            "\n",
            "Year: 2006\n",
            "'china' count: 28\n",
            "'russia' count: 16\n",
            "'ukraine' count: 3\n",
            "'assertive' count: 0\n",
            "--------------------\n",
            "\n",
            "Year: 2010\n",
            "'china' count: 10\n",
            "'russia' count: 12\n",
            "'ukraine' count: 0\n",
            "'assertive' count: 0\n",
            "--------------------\n",
            "\n",
            "Year: 2015\n",
            "'china' count: 12\n",
            "'russia' count: 8\n",
            "'ukraine' count: 5\n",
            "'assertive' count: 1\n",
            "--------------------\n",
            "\n",
            "Year: 2017\n",
            "'china' count: 33\n",
            "'russia' count: 22\n",
            "'ukraine' count: 1\n",
            "'assertive' count: 0\n",
            "--------------------\n",
            "\n",
            "Year: 2022\n",
            "'china' count: 9\n",
            "'russia' count: 58\n",
            "'ukraine' count: 32\n",
            "'assertive' count: 1\n",
            "--------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in nss_token_dict.keys():\n",
        "    print (\"Year: \" + str(i))\n",
        "    print(\"'china' count: \" + str(nss_token_dict[i][\"china\"]))\n",
        "    print(\"'russia' count: \" + str(nss_token_dict[i][\"russia\"]))\n",
        "    print(\"'ukraine' count: \" + str(nss_token_dict[i][\"ukraine\"]))\n",
        "    print(\"'assertive' count: \" + str(nss_token_dict[i][\"assertive\"]))\n",
        "    print(\"--------------------\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59177e54-f0ab-4125-b681-bb6f4b3661c0",
      "metadata": {
        "tags": [],
        "id": "59177e54-f0ab-4125-b681-bb6f4b3661c0"
      },
      "outputs": [],
      "source": [
        "def word_stats(data, stopwords=None, n=20): ##function is from class\n",
        "    type(stopwords)\n",
        "    if stopwords is not None:\n",
        "        for stop in stopwords:\n",
        "            del data[stop]\n",
        "    count_sum = 0\n",
        "    for token in data:\n",
        "        count_sum += data[token]\n",
        "    print(\"Total words in the text: \" + str(count_sum))\n",
        "    print(\"\")\n",
        "    print(\"Top \" + str(n) + \" words by frequency:\")\n",
        "    most_common = data.most_common()[:n]\n",
        "    for i in most_common:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304fbefd-8c8e-4ad6-83a1-49a7e0c0acc0",
      "metadata": {
        "id": "304fbefd-8c8e-4ad6-83a1-49a7e0c0acc0"
      },
      "outputs": [],
      "source": [
        "# helper function to apply function to dict\n",
        "\n",
        "def apply_to_dict(function, dict_to_use=nss_token_dict):\n",
        "    for i in dict_to_use.keys():\n",
        "        print(i)\n",
        "        function(dict_to_use[i])\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7223b281-f5c2-41ac-91fb-c6fb9f315128",
      "metadata": {
        "tags": [],
        "id": "7223b281-f5c2-41ac-91fb-c6fb9f315128",
        "outputId": "557b5008-c3ee-4a31-e8b8-6472b1ac03d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2002\n",
            "Total words in the text: 8932\n",
            "\n",
            "Top 20 words by frequency:\n",
            "('the', 418)\n",
            "('our', 123)\n",
            "('states', 118)\n",
            "('we', 108)\n",
            "('united', 88)\n",
            "('a', 74)\n",
            "('•', 71)\n",
            "('security', 70)\n",
            "('must', 61)\n",
            "('national', 60)\n",
            "('world', 58)\n",
            "('strategy', 50)\n",
            "('trade', 49)\n",
            "('to', 44)\n",
            "('global', 44)\n",
            "('new', 44)\n",
            "('freedom', 42)\n",
            "('america', 41)\n",
            "('in', 39)\n",
            "('economic', 39)\n",
            "\n",
            "2006\n",
            "Total words in the text: 13216\n",
            "\n",
            "Top 20 words by frequency:\n",
            "('the', 623)\n",
            "('•', 175)\n",
            "('a', 151)\n",
            "('states', 141)\n",
            "('security', 130)\n",
            "('united', 108)\n",
            "('we', 98)\n",
            "('national', 96)\n",
            "('strategy', 85)\n",
            "('our', 79)\n",
            "('must', 70)\n",
            "('world', 69)\n",
            "('in', 69)\n",
            "('international', 69)\n",
            "('freedom', 69)\n",
            "('economic', 64)\n",
            "('people', 62)\n",
            "('new', 61)\n",
            "('challenges', 59)\n",
            "('nations', 59)\n",
            "\n",
            "2010\n",
            "Total words in the text: 19144\n",
            "\n",
            "Top 20 words by frequency:\n",
            "('the', 708)\n",
            "('our', 353)\n",
            "('.', 349)\n",
            "('we', 281)\n",
            "('security', 273)\n",
            "('a', 193)\n",
            "('international', 189)\n",
            "('states', 155)\n",
            "('global', 151)\n",
            "('united', 143)\n",
            "('must', 128)\n",
            "('world', 121)\n",
            "('national', 115)\n",
            "('to', 110)\n",
            "('will', 102)\n",
            "('people', 94)\n",
            "('interests', 91)\n",
            "('nations', 89)\n",
            "('are', 87)\n",
            "('cooperation', 81)\n",
            "\n",
            "2015\n",
            "Total words in the text: 10566\n",
            "\n",
            "Top 20 words by frequency:\n",
            "('the', 398)\n",
            "('.', 388)\n",
            "('we', 206)\n",
            "('our', 173)\n",
            "('security', 126)\n",
            "('a', 105)\n",
            "('global', 85)\n",
            "('international', 77)\n",
            "('states', 65)\n",
            "('economic', 62)\n",
            "('world', 59)\n",
            "('will', 56)\n",
            "('national', 50)\n",
            "('continue', 50)\n",
            "('in', 47)\n",
            "('are', 46)\n",
            "('partners', 45)\n",
            "('support', 45)\n",
            "('to', 43)\n",
            "('american', 42)\n",
            "\n",
            "2017\n",
            "Total words in the text: 18007\n",
            "\n",
            "Top 20 words by frequency:\n",
            "('the', 572)\n",
            "('a', 297)\n",
            "('states', 294)\n",
            "('e', 293)\n",
            "('we', 265)\n",
            "('united', 233)\n",
            "('i', 210)\n",
            "('t', 204)\n",
            "('r', 196)\n",
            "('our', 184)\n",
            "('n', 179)\n",
            "('american', 123)\n",
            "('economic', 110)\n",
            "('l', 109)\n",
            "('partners', 109)\n",
            "('s', 107)\n",
            "('america', 106)\n",
            "('o', 103)\n",
            "('c', 95)\n",
            "('world', 92)\n",
            "\n",
            "2022\n",
            "Total words in the text: 17081\n",
            "\n",
            "Top 20 words by frequency:\n",
            "('the', 664)\n",
            "('we', 292)\n",
            "('a', 260)\n",
            "('our', 237)\n",
            "('t', 181)\n",
            "('cid:144', 156)\n",
            "('(', 136)\n",
            "('united', 134)\n",
            "('states', 134)\n",
            "(')', 134)\n",
            "('world', 130)\n",
            "('security', 121)\n",
            "('partners', 107)\n",
            "('global', 106)\n",
            "('will', 100)\n",
            "('i', 98)\n",
            "('international', 92)\n",
            "('n', 90)\n",
            "('s', 90)\n",
            "('e', 90)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "apply_to_dict(word_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5620cd52-79fb-41d9-9c64-aad56a6ae185",
      "metadata": {
        "id": "5620cd52-79fb-41d9-9c64-aad56a6ae185"
      },
      "source": [
        "### Vectorization and Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d60dc76-6ff4-408a-8757-33f5a3689acc",
      "metadata": {
        "tags": [],
        "id": "2d60dc76-6ff4-408a-8757-33f5a3689acc",
        "outputId": "5c9682d0-b29c-440c-db0d-740c01b843b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "      <th>year</th>\n",
              "      <th>text_tokenized</th>\n",
              "      <th>text_tokenized_stopwords</th>\n",
              "      <th>text_tokenized_stopwords_alphanumerical</th>\n",
              "      <th>text_tokenized_stopwords_alphanumerical_strings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nss2002.pdf</td>\n",
              "      <td>The National\\n\\nSecurity Strategy\\n\\nof the \\n...</td>\n",
              "      <td>2002</td>\n",
              "      <td>[the, national, security, strategy, united, st...</td>\n",
              "      <td>[the, national, security, strategy, united, st...</td>\n",
              "      <td>[the, national, security, strategy, united, st...</td>\n",
              "      <td>the national security strategy united states a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The National Security Strategy-- 2006.pdf</td>\n",
              "      <td>\\n\\n \\n\\n \\n\\n \\n\\nTABLE OF CONTENTS \\n\\nO...</td>\n",
              "      <td>2006</td>\n",
              "      <td>[table, of, contents, overview, america, natio...</td>\n",
              "      <td>[table, of, contents, overview, america, natio...</td>\n",
              "      <td>[table, of, contents, overview, america, natio...</td>\n",
              "      <td>table of contents overview america national se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NSS2010.pdf</td>\n",
              "      <td>NAT IONA L  SECU R IT Y \\n\\nSTR ATEGY\\n\\nMay 2...</td>\n",
              "      <td>2010</td>\n",
              "      <td>[nat, iona, l, secu, r, it, y, str, ategy, may...</td>\n",
              "      <td>[nat, iona, l, secu, r, it, y, str, ategy, may...</td>\n",
              "      <td>[nat, iona, l, secu, r, it, y, str, ategy, may...</td>\n",
              "      <td>nat iona l secu r it y str ategy may 2010 tabl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NSS2015.pdf</td>\n",
              "      <td>NATIONAL  SECURITY \\n\\nSTRATEGY\\n\\nF EBRUA RY ...</td>\n",
              "      <td>2015</td>\n",
              "      <td>[national, security, strategy, f, ebrua, ry, 2...</td>\n",
              "      <td>[national, security, strategy, f, ebrua, ry, 2...</td>\n",
              "      <td>[national, security, strategy, f, ebrua, ry, 2...</td>\n",
              "      <td>national security strategy f ebrua ry 2 015 th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NSS2017.pdf</td>\n",
              "      <td>N������� S������� \\n\\nS�������\\n\\nof the Unite...</td>\n",
              "      <td>2017</td>\n",
              "      <td>[united, states, america, d, e, c, e, m, b, e,...</td>\n",
              "      <td>[united, states, america, d, e, c, e, m, b, e,...</td>\n",
              "      <td>[united, states, america, d, e, c, e, m, b, e,...</td>\n",
              "      <td>united states america d e c e m b e r 2 0 1 7 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   file_name  \\\n",
              "0                                nss2002.pdf   \n",
              "1  The National Security Strategy-- 2006.pdf   \n",
              "2                                NSS2010.pdf   \n",
              "3                                NSS2015.pdf   \n",
              "4                                NSS2017.pdf   \n",
              "\n",
              "                                                text  year  \\\n",
              "0  The National\\n\\nSecurity Strategy\\n\\nof the \\n...  2002   \n",
              "1  \n",
              "\n",
              "\n",
              " \\n\\n \\n\\n \\n\\n \\n\\nTABLE OF CONTENTS \\n\\nO...  2006   \n",
              "2  NAT IONA L  SECU R IT Y \\n\\nSTR ATEGY\\n\\nMay 2...  2010   \n",
              "3  NATIONAL  SECURITY \\n\\nSTRATEGY\\n\\nF EBRUA RY ...  2015   \n",
              "4  N������� S������� \\n\\nS�������\\n\\nof the Unite...  2017   \n",
              "\n",
              "                                      text_tokenized  \\\n",
              "0  [the, national, security, strategy, united, st...   \n",
              "1  [table, of, contents, overview, america, natio...   \n",
              "2  [nat, iona, l, secu, r, it, y, str, ategy, may...   \n",
              "3  [national, security, strategy, f, ebrua, ry, 2...   \n",
              "4  [united, states, america, d, e, c, e, m, b, e,...   \n",
              "\n",
              "                            text_tokenized_stopwords  \\\n",
              "0  [the, national, security, strategy, united, st...   \n",
              "1  [table, of, contents, overview, america, natio...   \n",
              "2  [nat, iona, l, secu, r, it, y, str, ategy, may...   \n",
              "3  [national, security, strategy, f, ebrua, ry, 2...   \n",
              "4  [united, states, america, d, e, c, e, m, b, e,...   \n",
              "\n",
              "             text_tokenized_stopwords_alphanumerical  \\\n",
              "0  [the, national, security, strategy, united, st...   \n",
              "1  [table, of, contents, overview, america, natio...   \n",
              "2  [nat, iona, l, secu, r, it, y, str, ategy, may...   \n",
              "3  [national, security, strategy, f, ebrua, ry, 2...   \n",
              "4  [united, states, america, d, e, c, e, m, b, e,...   \n",
              "\n",
              "     text_tokenized_stopwords_alphanumerical_strings  \n",
              "0  the national security strategy united states a...  \n",
              "1  table of contents overview america national se...  \n",
              "2  nat iona l secu r it y str ategy may 2010 tabl...  \n",
              "3  national security strategy f ebrua ry 2 015 th...  \n",
              "4  united states america d e c e m b e r 2 0 1 7 ...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create string from text_tokenized_stopwords_alphanumerical\n",
        "\n",
        "text_tokenized_stopwords_alphanumerical_strings = []\n",
        "\n",
        "for i in nss_df[\"text_tokenized_stopwords_alphanumerical\"]:\n",
        "    text_tokenized_stopwords_alphanumerical_strings.append(\" \".join(i))\n",
        "\n",
        "\n",
        "nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"] = text_tokenized_stopwords_alphanumerical_strings\n",
        "nss_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3228817c-eab5-44a2-9900-abfc4c071ad3",
      "metadata": {
        "tags": [],
        "id": "3228817c-eab5-44a2-9900-abfc4c071ad3",
        "outputId": "368cb98b-8225-46c4-f154-147c7dafff60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2002\n",
            "{'neg': 0.175, 'neu': 0.54, 'pos': 0.285, 'compound': 1.0}\n",
            "-----------\n",
            "\n",
            "2006\n",
            "{'neg': 0.163, 'neu': 0.537, 'pos': 0.3, 'compound': 1.0}\n",
            "-----------\n",
            "\n",
            "2010\n",
            "{'neg': 0.107, 'neu': 0.592, 'pos': 0.301, 'compound': 1.0}\n",
            "-----------\n",
            "\n",
            "2015\n",
            "{'neg': 0.136, 'neu': 0.583, 'pos': 0.281, 'compound': 1.0}\n",
            "-----------\n",
            "\n",
            "2017\n",
            "{'neg': 0.139, 'neu': 0.561, 'pos': 0.3, 'compound': 1.0}\n",
            "-----------\n",
            "\n",
            "2022\n",
            "{'neg': 0.113, 'neu': 0.607, 'pos': 0.28, 'compound': 1.0}\n",
            "-----------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sent_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "#print(sent_analyzer.polarity_scores(c_docs_text))#[\"neg\"])\n",
        "for i in range(len(nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"])):\n",
        "    print(nss_df[\"year\"].iloc[i])\n",
        "    print(sent_analyzer.polarity_scores(nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"].iloc[i]))\n",
        "    print(\"-----------\")\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d33fe33-0637-413a-99b2-01698a4bfc72",
      "metadata": {
        "tags": [],
        "id": "2d33fe33-0637-413a-99b2-01698a4bfc72"
      },
      "outputs": [],
      "source": [
        "assertive_list = [\"assertive\", \"asserts\", \"threatens\", \"security\", \"threat\", \"revisionist\", \"taiwan\", \"china sea\"]\n",
        "assertive_dict = {}\n",
        "\n",
        "for i in nss_token_dict.keys():\n",
        "    counter = Counter()\n",
        "    for j in assertive_list:\n",
        "        counter[j] = nss_token_dict[i][j]\n",
        "        assertive_dict[i] = counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4afe387c-ba6d-4503-a4da-79d2e4565063",
      "metadata": {
        "tags": [],
        "id": "4afe387c-ba6d-4503-a4da-79d2e4565063",
        "outputId": "1b416531-c9ac-45ec-e938-04af1c076c47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'security': 70,\n",
              "         'threat': 17,\n",
              "         'taiwan': 4,\n",
              "         'threatens': 2,\n",
              "         'assertive': 0,\n",
              "         'asserts': 0,\n",
              "         'revisionist': 0,\n",
              "         'china sea': 0})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assertive_dict[\"2002\"] #how to preserve order? for regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630db020-182b-4a90-9154-1591c783a279",
      "metadata": {
        "tags": [],
        "id": "630db020-182b-4a90-9154-1591c783a279",
        "outputId": "70b32640-3672-409a-c13d-ace36880fdfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "year:  2002\n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.175\n",
            "year:  2006\n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.163\n",
            "year:  2010\n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.107\n",
            "year:  2015\n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.136\n",
            "year:  2017\n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.139\n",
            "year:  2022\n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.113\n"
          ]
        }
      ],
      "source": [
        "for i in assertive_dict.keys():\n",
        "    X=[]\n",
        "    for j in assertive_dict[i]:\n",
        "        X.append(assertive_dict[i][j])\n",
        "    X = np.array(X).reshape(1,-1)\n",
        "    curr_index = nss_df[\"year\"].tolist().index(i)\n",
        "    y= [sent_analyzer.polarity_scores(nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"].iloc[curr_index])[\"neg\"]]\n",
        "    log_model = LinearRegression().fit(X=X, y=y)\n",
        "    print(\"year: \", i)\n",
        "    print(log_model.coef_)\n",
        "    print(log_model.intercept_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb580468-0a2a-448f-9479-1242e06e296b",
      "metadata": {
        "id": "eb580468-0a2a-448f-9479-1242e06e296b"
      },
      "source": [
        "## Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6730abd-16e4-4946-8b0f-fee31404bd44",
      "metadata": {
        "tags": [],
        "id": "d6730abd-16e4-4946-8b0f-fee31404bd44"
      },
      "outputs": [],
      "source": [
        "sp_model = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a193130-ed2a-45eb-90e9-b4dc83d1b15f",
      "metadata": {
        "tags": [],
        "id": "1a193130-ed2a-45eb-90e9-b4dc83d1b15f"
      },
      "outputs": [],
      "source": [
        "def get_doc_embedding(input_str, spacy_obj=sp_model):\n",
        "    text_loaded = spacy_obj(input_str)\n",
        "    word_embedding_vector = []\n",
        "    curr_vector = []\n",
        "\n",
        "    for i in text_loaded:\n",
        "        if (i.is_stop or i.is_punct or i.is_space) == False and i.has_vector == True:\n",
        "            curr_vector = i.vector\n",
        "            word_embedding_vector.append(curr_vector)\n",
        "\n",
        "    return_vector = np.mean(word_embedding_vector, axis=0)\n",
        "    return(return_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fca47e-dc8d-4c85-98ba-d247a225d834",
      "metadata": {
        "tags": [],
        "id": "73fca47e-dc8d-4c85-98ba-d247a225d834"
      },
      "outputs": [],
      "source": [
        "embedding_vector= np.zeros((6, 300))\n",
        "\n",
        "for i in range(len( nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"])):\n",
        "    embedding_vector[i] = get_doc_embedding(nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"].iloc[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed7478a-3613-42f1-b8ac-22b237566aa0",
      "metadata": {
        "tags": [],
        "id": "9ed7478a-3613-42f1-b8ac-22b237566aa0",
        "outputId": "1719cdce-5755-44b8-ccd2-c0a763f4aad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 300)\n"
          ]
        }
      ],
      "source": [
        "##embedding_vector = np.einsum(\"ij->ji\", embedding_vector) #https://stackoverflow.com/questions/23943379/swapping-the-dimensions-of-a-numpy-array\n",
        "print(embedding_vector.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304088c2-114b-4229-ab37-45b87afd402e",
      "metadata": {
        "tags": [],
        "id": "304088c2-114b-4229-ab37-45b87afd402e",
        "outputId": "f9b6970d-f595-40c5-c149-3a6a3dcf6afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.175 0.163 0.107 0.136 0.139 0.113]\n"
          ]
        }
      ],
      "source": [
        "y_sentiment_score = []\n",
        "for i in range(len(nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"])):\n",
        "    y_sentiment_score.append(sent_analyzer.polarity_scores(nss_df[\"text_tokenized_stopwords_alphanumerical_strings\"].iloc[i])[\"neg\"])\n",
        "y_sentiment_score = np.array(y_sentiment_score)\n",
        "print(y_sentiment_score)\n",
        "\n",
        "\n",
        "#np.mean(cross_val_score(LogisticRegression(), embedding_vector, np.array(nss_df[\"year\"]), cv=2, scoring=\"accuracy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae2a9c1-65c3-4026-a22b-33033cc03943",
      "metadata": {
        "tags": [],
        "id": "fae2a9c1-65c3-4026-a22b-33033cc03943",
        "outputId": "933f0aa6-b056-4e36-b806-e68d516f4538"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['2002', '2006', '2010', '2015', '2017', '2022'], dtype=object)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(nss_df[\"year\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c8019d-3e90-4be8-a281-e813e67092a3",
      "metadata": {
        "tags": [],
        "id": "04c8019d-3e90-4be8-a281-e813e67092a3"
      },
      "outputs": [],
      "source": [
        "# Saving nss_df to CSV to work on BERT-based embeddings, will continue work below at a later stage\n",
        "\n",
        "nss_df.to_csv(\"nss.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05063d42-66d0-43a6-91e4-fafa4580d0d8",
      "metadata": {
        "tags": [],
        "id": "05063d42-66d0-43a6-91e4-fafa4580d0d8",
        "outputId": "c0944613-6752-4d30-bc50-04214b9bed44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Jullen18/opt/anaconda3/envs/3350/lib/python3.11/site-packages/sklearn/decomposition/_truncated_svd.py:268: RuntimeWarning: invalid value encountered in divide\n",
            "  self.explained_variance_ratio_ = exp_var / full_var\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "only integer scalar arrays can be converted to a scalar index",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m arr_i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(i)\n\u001b[1;32m      6\u001b[0m to_input \u001b[38;5;241m=\u001b[39m arr_i\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m embeddings_trunc[i] \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(to_input)\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ],
      "source": [
        "## reducing dimensionality for plotting\n",
        "embeddings_trunc = []\n",
        "svd = TruncatedSVD()\n",
        "for i in embedding_vector:\n",
        "    arr_i = np.array(i)\n",
        "    to_input = arr_i.reshape(1,-1)\n",
        "    embeddings_trunc[i] = svd.fit_transform(to_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04870b5e-c92f-42e9-aa32-b682bf5167af",
      "metadata": {
        "tags": [],
        "id": "04870b5e-c92f-42e9-aa32-b682bf5167af"
      },
      "outputs": [],
      "source": [
        "embeddings_trunc = svd.fit_transform(embedding_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18d8600-6cf9-4ca7-8de7-9ee575f6c866",
      "metadata": {
        "id": "d18d8600-6cf9-4ca7-8de7-9ee575f6c866"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ecdba03-4008-467c-a5d2-7cfe03a9ce63",
      "metadata": {
        "tags": [],
        "id": "9ecdba03-4008-467c-a5d2-7cfe03a9ce63",
        "outputId": "989a6b97-8fef-410e-a270-d180017c9fa4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "years = nss_df[\"year\"]\n",
        "plt = sns.scatterplot(x= embeddings_trunc[:,0], y=embeddings_trunc[:,1], hue=embeddings_trunc[:,1], legend=None)\n",
        "\n",
        "for i, txt in enumerate(years):\n",
        "    plt.text(embeddings_trunc[:,0][i], embeddings_trunc[:,1][i], txt) #inspired by: https://python-charts.com/seaborn/texts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f634290b-d7e9-4d2c-a915-c7261c8823dd",
      "metadata": {
        "id": "f634290b-d7e9-4d2c-a915-c7261c8823dd"
      },
      "outputs": [],
      "source": [
        "nss_df[\"text\"].iloc[0][:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13772461-21c3-4143-947c-7d57233dc3f9",
      "metadata": {
        "tags": [],
        "id": "13772461-21c3-4143-947c-7d57233dc3f9"
      },
      "outputs": [],
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') #inspired by: https://stackoverflow.com/questions/4576077/how-can-i-split-a-text-into-sentences\n",
        "#fp = open(\"test.txt\")\n",
        "#data = fp.read()\n",
        "print(tokenizer.tokenize(nss_df[\"text\"].iloc[0][:500]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23674eb-ec23-42ed-a3f6-6701015346f3",
      "metadata": {
        "tags": [],
        "id": "b23674eb-ec23-42ed-a3f6-6701015346f3"
      },
      "outputs": [],
      "source": [
        "sentence_list = []\n",
        "for i in nss_df[\"text\"]:\n",
        "    sentence_list.append(tokenizer.tokenize(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53e52c9-5858-4636-b189-4269fd65a3a3",
      "metadata": {
        "tags": [],
        "id": "a53e52c9-5858-4636-b189-4269fd65a3a3"
      },
      "outputs": [],
      "source": [
        "sentence_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95fcba44-3fac-447d-b81e-54ed9c172525",
      "metadata": {
        "tags": [],
        "id": "95fcba44-3fac-447d-b81e-54ed9c172525"
      },
      "outputs": [],
      "source": [
        "document_embeddings_by_sentence = []\n",
        "\n",
        "for i in sentence_list[0]:\n",
        "    list_to_append = []\n",
        "    for j in i:\n",
        "        list_to_append.append(get_doc_embedding(j))\n",
        "    document_embeddings_by_sentence.append(list_to_append)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71536241-80c3-4b03-b1d6-c1279469c144",
      "metadata": {
        "tags": [],
        "id": "71536241-80c3-4b03-b1d6-c1279469c144"
      },
      "outputs": [],
      "source": [
        "#document_embeddings_by_sentence = []\n",
        "document_1_embeddings_by_sentence = []\n",
        "\n",
        "for i in sentence_list[0]:\n",
        "    document_1_embeddings_by_sentence.append(get_doc_embedding(i))\n",
        "    document_1_embeddings_by_sentence = [document_1_embeddings_by_sentence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e0e45d-aa88-483d-9562-d0703a0824ac",
      "metadata": {
        "tags": [],
        "id": "a4e0e45d-aa88-483d-9562-d0703a0824ac"
      },
      "outputs": [],
      "source": [
        "trunc_sent_embeddings = svd.fit(document_1_embeddings_by_sentence)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}